import warnings
warnings.filterwarnings('ignore', category=FutureWarning)

import os
import torch
import logging
# ã€å¼•å…¥çº§è”æ¨¡å‹æ‰€éœ€çš„ç»„ä»¶ã€‘
from ultralytics.models.yolo.detect import DetectionTrainer
from ultralytics.nn.tasks import CascadeDetectionModel
from ultralytics.utils.loss import CascadeLoss
from ultralytics.utils import LOGGER 

# ==============================================================================
# ----------------- æ˜¾å¡è‡ªåŠ¨æ£€æµ‹ä¸è®¾ç½® -----------------
# ==============================================================================
# å»ºè®®ï¼šä¸è¦åœ¨ä»£ç é‡Œç¡¬ç¼–ç  os.environ['CUDA_VISIBLE_DEVICES']ï¼Œè¿™å®¹æ˜“å¯¼è‡´æ‰¾ä¸åˆ°æ˜¾å¡ã€‚
# å¦‚æœä½ æƒ³æŒ‡å®šæ˜¾å¡ï¼Œå»ºè®®åœ¨è¿è¡Œå‘½ä»¤å‰åŠ ï¼Œä¾‹å¦‚: CUDA_VISIBLE_DEVICES=1 python train_cascade.py

def check_gpu_availability():
    """æ£€æŸ¥å¹¶æ‰“å°å½“å‰å¯ç”¨çš„GPUä¿¡æ¯"""
    print(f"\n[GPU æ£€æµ‹] PyTorchç‰ˆæœ¬: {torch.__version__}")
    if torch.cuda.is_available():
        cnt = torch.cuda.device_count()
        print(f"[GPU æ£€æµ‹] å‘ç° {cnt} ä¸ªå¯ç”¨ GPU:")
        for i in range(cnt):
            print(f"  - index {i}: {torch.cuda.get_device_name(i)}")
        return True
    else:
        print("[GPU æ£€æµ‹] âŒ æœªå‘ç°å¯ç”¨ GPUï¼Œå°†ä½¿ç”¨ CPU è®­ç»ƒ (é€Ÿåº¦ä¼šå¾ˆæ…¢)")
        return False

# ==============================================================================
# ----------------- è‡ªå®šä¹‰ CascadeTrainer ç±» -----------------
# ==============================================================================
class CascadeTrainer(DetectionTrainer):
    """
    è‡ªå®šä¹‰è®­ç»ƒå™¨ï¼Œç”¨äºæ”¯æŒ CascadeDetectionModel å’Œ CascadeLoss
    """
    def get_model(self, cfg=None, weights=None, verbose=True):
        """
        é‡å†™ get_modelï¼Œå¼ºåˆ¶ä½¿ç”¨ CascadeDetectionModel
        """
        # åˆ›å»º CascadeDetectionModel å®ä¾‹
        model = CascadeDetectionModel(cfg, nc=self.data["nc"], verbose=verbose)
        if weights:
            model.load(weights)
        return model

    def get_loss(self):
        """
        é‡å†™ get_lossï¼Œä½¿ç”¨è‡ªå®šä¹‰çš„ CascadeLoss
        """
        return CascadeLoss(self.model)

# ==============================================================================
# ----------------- æ—¥å¿—ä¸è·¯å¾„å·¥å…·å‡½æ•° -----------------
# ==============================================================================
def get_unique_dir(project_dir, base_name):
    """ç¡®ä¿è·å–ä¸€ä¸ªå”¯ä¸€çš„æ–‡ä»¶å¤¹è·¯å¾„"""
    run_path = os.path.join(project_dir, base_name)
    if not os.path.exists(run_path):
        return run_path
    i = 2
    while True:
        unique_name = f"{base_name}{i}"
        run_path = os.path.join(project_dir, unique_name)
        if not os.path.exists(run_path):
            return run_path
        i += 1

def run_training_task(model_yaml_path, data_yaml_path, device_id='0', train_params=None):
    if train_params is None:
        train_params = {}

    project_dir = 'runs/train/'
    base_run_name = os.path.splitext(os.path.basename(model_yaml_path))[0]
    final_save_dir = get_unique_dir(project_dir, base_run_name)
    
    os.makedirs(final_save_dir, exist_ok=True)
    log_file_path = os.path.join(final_save_dir, 'train_log.txt')
    
    # é…ç½®æ–‡ä»¶æ—¥å¿—å¤„ç†å™¨
    file_handler = logging.FileHandler(log_file_path, mode='w', encoding='utf-8')
    file_handler.setFormatter(logging.Formatter('%(message)s'))
    LOGGER.addHandler(file_handler)

    try:
        LOGGER.info(f"============================================================")
        LOGGER.info(f"ğŸš€ [çº§è”ä»»åŠ¡å¼€å§‹] å‡†å¤‡è®­ç»ƒæ¨¡å‹: {base_run_name}")
        LOGGER.info(f"   - ç»“æœå°†ä¿å­˜åœ¨: {final_save_dir}")
        LOGGER.info(f"   - å®Œæ•´æ—¥å¿—å°†å†™å…¥: {log_file_path}")
        LOGGER.info(f"   - è¯·æ±‚ä½¿ç”¨è®¾å¤‡: {device_id}")
        LOGGER.info(f"============================================================")
        
        # 1. ç»„è£…å‚æ•°
        args = {
            'model': model_yaml_path,
            'data': data_yaml_path,
            'project': os.path.dirname(final_save_dir),
            'name': os.path.basename(final_save_dir),
            'device': device_id,
            'exist_ok': True,
            **train_params 
        }

        # 2. å®ä¾‹åŒ–è‡ªå®šä¹‰è®­ç»ƒå™¨
        trainer = CascadeTrainer(overrides=args)

        # 3. å¼€å§‹è®­ç»ƒ
        trainer.train()
        
        LOGGER.info(f"\nâœ… [ä»»åŠ¡å®Œæˆ] æ¨¡å‹ {base_run_name} è®­ç»ƒç»“æŸï¼")

    except Exception as e:
        LOGGER.error(f"\nâŒ [è®­ç»ƒå‡ºé”™] ä»»åŠ¡ '{base_run_name}' å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)

    finally:
        LOGGER.removeHandler(file_handler)
        file_handler.close()
        print(f"ğŸ“„ ä»»åŠ¡ '{base_run_name}' çš„å®Œæ•´æ—¥å¿—å·²ä¿å­˜è‡³: {log_file_path}")
        print(f"============================================================\n")


# ==============================================================================
#                             ä¸»ç¨‹åºå…¥å£
# ==============================================================================
if __name__ == '__main__':
    # 1. å…ˆæ£€æŸ¥æ˜¾å¡
    check_gpu_availability()

    DATASET_CONFIG = '/home/liuyadong/ultralytics-main-cascade-2/ultralytics/cfg/datasets/VisDrone.yaml'
    
    # ã€ä¿®æ”¹è¿™é‡Œã€‘
    # å»ºè®®ä½¿ç”¨ '0'ï¼Œultralytics ä¼šè‡ªåŠ¨æ‰¾åˆ°ç¬¬ä¸€å—å¯ç”¨çš„æ˜¾å¡ã€‚
    # å¦‚æœä½ æœ‰å¤šä¸ªæ˜¾å¡æƒ³ç”¨ç¬¬äºŒå—ï¼Œå¯ä»¥åœ¨è¿è¡Œè„šæœ¬æ—¶åœ¨å‘½ä»¤è¡ŒæŒ‡å®šï¼š
    # CUDA_VISIBLE_DEVICES=1 python train_cascade.py
    # æ­¤æ—¶ä»£ç é‡Œçš„ GPU_DEVICE ä¾ç„¶å¡« '0' å³å¯ï¼ˆå› ä¸ºå¯¹äºç¨‹åºæ¥è¯´å®ƒæ˜¯ç¬¬0å—å¯è§çš„å¡ï¼‰
    GPU_DEVICE = '0' 

    model_config_1 = '/home/liuyadong/ultralytics-main-cascade-2/yolo12s-cascade-EALF.yaml'
    
    params_for_task_1 = {
        'imgsz': 640, 
        'epochs': 300, 
        'batch': 16, 
        'workers': 4,
        'optimizer': 'SGD', 
        'cache': False, 
        'close_mosaic': 0,
        'seed': 42,
        'lr0': 0.01,
        'cos_lr': True
    }
    
    run_training_task(
        model_yaml_path=model_config_1, data_yaml_path=DATASET_CONFIG,
        device_id=GPU_DEVICE, train_params=params_for_task_1
    )