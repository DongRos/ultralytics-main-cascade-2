import torch
import torch.nn.functional as F
import cv2
import numpy as np
import os
from ultralytics.nn.tasks import CascadeDetectionModel
from ultralytics.utils.torch_utils import select_device

def apply_stn_to_rgb(img_tensor, gaze_params):
    """
    æ‰‹åŠ¨å¯¹ RGB åŸå›¾åº”ç”¨ STN å˜æ¢
    """
    B, C, H, W = img_tensor.size()
    tx = gaze_params[:, 0]
    ty = gaze_params[:, 1]
    s  = gaze_params[:, 2]

    tx_trans = (tx - 0.5) * 2
    ty_trans = (ty - 0.5) * 2
    
    theta = torch.zeros(B, 2, 3, device=img_tensor.device)
    theta[:, 0, 0] = s
    theta[:, 1, 1] = s
    theta[:, 0, 2] = tx_trans
    theta[:, 1, 2] = ty_trans

    grid = F.affine_grid(theta, img_tensor.size(), align_corners=False)
    warped_rgb = F.grid_sample(img_tensor, grid, mode='bilinear', padding_mode='zeros', align_corners=False)
    return warped_rgb

def visualize_stn(img_path, model_cfg, weights_path, device='0'):
    # 1. å‡†å¤‡ç¯å¢ƒ
    device = select_device(device)
    save_dir = 'runs/stn_visualization'
    if os.path.exists(save_dir):
        import shutil
        shutil.rmtree(save_dir)
    os.makedirs(save_dir)
    
    print(f"ğŸš€ å¼€å§‹ STN å¯è§†åŒ–...")
    
    # 2. åŠ è½½æ¨¡å‹
    model = CascadeDetectionModel(cfg=model_cfg, nc=10, verbose=False)
    if weights_path and os.path.exists(weights_path):
        ckpt = torch.load(weights_path, map_location=device)
        model.load_state_dict(ckpt['model'].float().state_dict())
        print("âœ… æƒé‡åŠ è½½æˆåŠŸ")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æƒé‡ï¼Œä½¿ç”¨éšæœºå‚æ•°")
    
    model.to(device).eval()

    # --- [å…³é”®ä¿®å¤] è‡ªåŠ¨æŸ¥æ‰¾å±‚ç´¢å¼• ---
    stn_layer_idx = -1
    coarse_layer_idx = -1
    
    print("\nğŸ” æ­£åœ¨è‡ªåŠ¨å®šä½æ¨¡å—å±‚ç´¢å¼•...")
    for i, m in enumerate(model.model):
        name = m.__class__.__name__
        if name == 'DifferentiableGazeShift':
            stn_layer_idx = i
            print(f"  -> æ‰¾åˆ° STN (DifferentiableGazeShift): Layer {i}")
        elif name == 'CoarseDetect':
            coarse_layer_idx = i
            print(f"  -> æ‰¾åˆ° CoarseDetect: Layer {i}")
            
    if stn_layer_idx == -1 or coarse_layer_idx == -1:
        print("âŒ é”™è¯¯ï¼šæ— æ³•åœ¨æ¨¡å‹ä¸­æ‰¾åˆ° CoarseDetect æˆ– STN æ¨¡å—ï¼è¯·æ£€æŸ¥ YAML é…ç½®ã€‚")
        return
    # -------------------------------

    # 3. æ³¨å†Œ Hook (STN)
    captured_data = {'params': None, 'features': []}

    def hook_fn(module, input, output):
        # [é˜²å¾¡æ€§æ£€æŸ¥] é˜²æ­¢ input[1] è¶Šç•Œ
        if len(input) > 1:
            captured_data['params'] = input[1].detach()
        else:
            print(f"âš ï¸ Warning: STN Layer {stn_layer_idx} ä»…æ¥æ”¶åˆ° 1 ä¸ªè¾“å…¥ã€‚tasks.py é€»è¾‘å¯èƒ½æœªç”Ÿæ•ˆã€‚")
            # å°è¯•é€ ä¸€ä¸ªå‡å‚æ•°é˜²æ­¢è„šæœ¬å´©æºƒ
            captured_data['params'] = torch.tensor([[0.5, 0.5, 1.0]], device=input[0].device)
            
        captured_data['features'] = output
    
    model.model[stn_layer_idx].register_forward_hook(hook_fn)

    # 4. å›¾åƒé¢„å¤„ç†
    original_cv_img = cv2.imread(img_path)
    if original_cv_img is None:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°å›¾ç‰‡: {img_path}")
        
    h0, w0 = original_cv_img.shape[:2]
    img = cv2.resize(original_cv_img, (640, 640))
    img_in = img[:, :, ::-1].transpose(2, 0, 1)
    img_in = np.ascontiguousarray(img_in)
    img_tensor = torch.from_numpy(img_in).to(device).float() / 255.0
    img_tensor = img_tensor[None]

    # 5. è¿è¡Œæ¨ç†
    with torch.no_grad():
        model(img_tensor)

    # 6. å¯è§†åŒ–å‚æ•° & RGB åˆ‡ç‰‡
    params = captured_data['params']
    if params is None: return

    tx, ty, s = params[0].tolist()
    print(f"\nğŸ” [CoarseDetect å†³ç­–ç»“æœ]")
    print(f"   - ä¸­å¿ƒç‚¹: ({tx:.4f}, {ty:.4f})")
    print(f"   - ç¼©æ”¾å› å­: {s:.4f}")
    print(f"   => è§†çº¿åæ ‡: ({tx*w0:.0f}, {ty*h0:.0f})")

    rgb_crop_tensor = apply_stn_to_rgb(img_tensor, params)
    rgb_crop = rgb_crop_tensor[0].cpu().numpy().transpose(1, 2, 0)
    rgb_crop = (rgb_crop * 255).astype(np.uint8)
    rgb_crop = cv2.cvtColor(rgb_crop, cv2.COLOR_RGB2BGR)
    
    cv2.imwrite(f"{save_dir}/1_RGB_Real_Crop.jpg", rgb_crop)
    display_img = np.hstack([img, rgb_crop])
    cv2.imwrite(f"{save_dir}/0_Comparison_RGB.jpg", display_img)
    print(f"âœ… ä¿å­˜ RGB å¯¹æ¯”å›¾: {save_dir}/0_Comparison_RGB.jpg")

    # 7. å¯è§†åŒ– Saliency Map (ç¬¬äºŒæ¬¡æ¨ç† Hook CoarseDetect)
    coarse_data = {'out': None}
    def coarse_hook(module, input, output):
        coarse_data['out'] = output
    
    # ç§»é™¤æ—§ Hookï¼Œæ³¨å†Œæ–° Hook
    # model.model[stn_layer_idx].remove_hook() # PyTorch æ—§ç‰ˆæœ¬å¯èƒ½ä¸æ”¯æŒï¼Œè¿™é‡Œé‡æ–°æ¨ç†ä¸€æ¬¡æ— å¦¨
    model.model[coarse_layer_idx].register_forward_hook(coarse_hook)
    
    with torch.no_grad():
        model(img_tensor)
        
    if coarse_data['out'] is not None:
        # coarse_outputs[0] æ˜¯åˆ†è¾¨ç‡æœ€é«˜çš„ç‰¹å¾ (P2 æˆ– P3)
        raw_feat = coarse_data['out'][0] 
        saliency = raw_feat[0, 0].cpu().numpy()
        
        saliency_norm = (saliency - saliency.min()) / (saliency.max() - saliency.min() + 1e-8)
        heatmap = cv2.applyColorMap((saliency_norm * 255).astype(np.uint8), cv2.COLORMAP_JET)
        heatmap = cv2.resize(heatmap, (w0, h0))
        
        overlay = cv2.addWeighted(original_cv_img, 0.6, heatmap, 0.4, 0)
        cv2.imwrite(f"{save_dir}/-1_Saliency_Map_Overlay.jpg", overlay)
        print(f"ğŸ”¥ ä¿å­˜çƒ­åŠ›å›¾: {save_dir}/-1_Saliency_Map_Overlay.jpg")

    # 8. å¯è§†åŒ–ç‰¹å¾å›¾åˆ‡ç‰‡
    feature_maps = captured_data['features']
    if isinstance(feature_maps, list):
        for i, feat in enumerate(feature_maps):
            heatmap = torch.mean(feat[0], dim=0).cpu().numpy()
            heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)
            heatmap_color = cv2.applyColorMap((heatmap * 255).astype(np.uint8), cv2.COLORMAP_JET)
            heatmap_view = cv2.resize(heatmap_color, (320, 320), interpolation=cv2.INTER_NEAREST)
            cv2.imwrite(f"{save_dir}/2_Feature_Crop_Level_{i}.jpg", heatmap_view)

    print("\nğŸ‰ å¯è§†åŒ–å®Œæˆï¼")

if __name__ == '__main__':
    # æ›¿æ¢è·¯å¾„
    img_path = '/home/liuyadong/ultralytics-main-cascade/å›¾ç‰‡ç´ æ/0000146_01678_d_0000066.jpg'
    
    # è¯·ç¡®ä¿ yaml æ–‡ä»¶å’Œä½ è®­ç»ƒæƒé‡æ˜¯å¯¹åº”çš„ (P2ç‰ˆç”¨P2 yaml)
    visualize_stn(
        img_path=img_path,
        model_cfg='/home/liuyadong/ultralytics-main-cascade/yolo12s-cascade.yaml', 
        weights_path='/home/liuyadong/ultralytics-main-cascade/runs/train/yolo12s-cascade2-å¤šå°ºåº¦åŠ å¤šå¤„P2/weights/best.pt'
    )